{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a74b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authors\n",
    "#Ganesh Sarla\n",
    "#Sai Akhil Gourvarapu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4014be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constant values\n",
    "headers = [\"Fold\", \"Accuracy (Logistic)\", \"Accuracy (SVM)\", \"Accuracy (Random Forest)\",\n",
    "           \"F1 Score (Logistic)\", \"F1 Score (SVM)\", \"F1 Score (Random Forest)\",\n",
    "           \"Time (Logistic)\", \"Time (SVM)\", \"Time (Random Forest)\"]\n",
    "final_rank_headers = [\"Classifier\", \"Accuracy Rank\", \"F1 Score Rank\", \"Time Rank\"]\n",
    "K_fold = 10\n",
    "iteration = 0\n",
    "k=3\n",
    "n=K_fold\n",
    "Sum_of_squared_differences_for_accuracy_1=0\n",
    "Sum_of_squared_differences_for_accuracy_2=0\n",
    "Sum_of_squared_differences_for_f1_1=0\n",
    "Sum_of_squared_differences_for_f1_2=0\n",
    "Sum_of_squared_differences_for_Time_1=0\n",
    "Sum_of_squared_differences_for_Time_2=0\n",
    "critical_value=7.8\n",
    "q=2.343\n",
    "Classifiers = [\"Logistic Regression\", \"SVM\", \"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897dcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\",\n",
    "                \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\",\n",
    "                \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n",
    "                \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
    "                \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\",\n",
    "                \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\",\n",
    "                \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\",\n",
    "                \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \"word_freq_cs\", \"word_freq_meeting\",\n",
    "                \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\",\n",
    "                \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\",\n",
    "                \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\",\n",
    "                \"spam_class\"]\n",
    "data = pd.read_csv('spambase.data', names=column_names)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(\"spam_class\", axis=1)\n",
    "Y = data[\"spam_class\"]\n",
    "\n",
    "# Define classifiers\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(gamma=\"auto\"))\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "logic_classifier = LogisticRegression(max_iter=5000)\n",
    "cv = StratifiedKFold(n_splits=K_fold, shuffle=True, random_state=1)\n",
    "\n",
    "# Set up arrays to hold performance metric values upon initialization.\n",
    "Data_of_accuracy = np.zeros((K_fold, 3))\n",
    "Data_of_f1 = np.zeros((K_fold, 3))\n",
    "Data_of_time = np.zeros((K_fold, 3))\n",
    "\n",
    "# Set up arrays with initial values to hold the performance metrics ranks.\n",
    "accuracy_ranks = np.zeros((K_fold, 3))\n",
    "f1_ranks = np.zeros((K_fold, 3))\n",
    "time_ranks = np.zeros((K_fold, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074a4304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: [0.92849807 0.93349382 0.95414175]\n",
      "Standard Deviation Accuracy: [0.0112383  0.00842124 0.00722971]\n",
      "\n",
      "Average F1 Score: [0.90771262 0.91392753 0.94090806]\n",
      "Standard Deviation F1 Score: [0.01451257 0.01109659 0.00925153]\n",
      "\n",
      "Average Time: [1.46348414 0.30664206 1.28122416]\n",
      "Standard Deviation Time: [0.35243552 0.0936425  0.1651338 ]\n",
      "\n",
      "Fold Data:\n",
      "   Fold  Accuracy (Logistic)  Accuracy (SVM)  Accuracy (Random Forest)  \\\n",
      "0     1             0.908894        0.928416                  0.947939   \n",
      "1     2             0.939130        0.941304                  0.950000   \n",
      "2     3             0.926087        0.934783                  0.947826   \n",
      "3     4             0.930435        0.932609                  0.950000   \n",
      "4     5             0.939130        0.934783                  0.960870   \n",
      "5     6             0.917391        0.921739                  0.958696   \n",
      "6     7             0.947826        0.952174                  0.963043   \n",
      "7     8             0.932609        0.936957                  0.941304   \n",
      "8     9             0.926087        0.928261                  0.958696   \n",
      "9    10             0.917391        0.923913                  0.963043   \n",
      "\n",
      "   F1 Score (Logistic)  F1 Score (SVM)  F1 Score (Random Forest)  \\\n",
      "0             0.882022        0.907042                  0.931818   \n",
      "1             0.920904        0.923944                  0.934844   \n",
      "2             0.903955        0.915730                  0.931429   \n",
      "3             0.909091        0.912676                  0.936639   \n",
      "4             0.919540        0.914773                  0.950276   \n",
      "5             0.892655        0.897143                  0.946176   \n",
      "6             0.932584        0.937500                  0.952646   \n",
      "7             0.916442        0.920981                  0.926431   \n",
      "8             0.906077        0.908078                  0.946176   \n",
      "9             0.893855        0.901408                  0.952646   \n",
      "\n",
      "   Time (Logistic)  Time (SVM)  Time (Random Forest)  \n",
      "0         1.654121    0.396711              1.148065  \n",
      "1         1.494862    0.279691              1.271247  \n",
      "2         2.064347    0.329732              1.299567  \n",
      "3         1.024400    0.344269              1.381149  \n",
      "4         0.869738    0.199885              1.139952  \n",
      "5         1.804819    0.504992              1.209885  \n",
      "6         1.521266    0.208625              1.162798  \n",
      "7         1.708632    0.200275              1.242201  \n",
      "8         1.136426    0.250231              1.729647  \n",
      "9         1.356230    0.352010              1.227731  \n",
      "\n",
      "Rank Data:\n",
      "   Fold  Accuracy (Logistic)  Accuracy (SVM)  Accuracy (Random Forest)  \\\n",
      "0     1                  3.0             2.0                       1.0   \n",
      "1     2                  3.0             2.0                       1.0   \n",
      "2     3                  3.0             2.0                       1.0   \n",
      "3     4                  3.0             2.0                       1.0   \n",
      "4     5                  2.0             3.0                       1.0   \n",
      "5     6                  3.0             2.0                       1.0   \n",
      "6     7                  3.0             2.0                       1.0   \n",
      "7     8                  3.0             2.0                       1.0   \n",
      "8     9                  3.0             2.0                       1.0   \n",
      "9    10                  3.0             2.0                       1.0   \n",
      "\n",
      "   F1 Score (Logistic)  F1 Score (SVM)  F1 Score (Random Forest)  \\\n",
      "0                  3.0             2.0                       1.0   \n",
      "1                  3.0             2.0                       1.0   \n",
      "2                  3.0             2.0                       1.0   \n",
      "3                  3.0             2.0                       1.0   \n",
      "4                  2.0             3.0                       1.0   \n",
      "5                  3.0             2.0                       1.0   \n",
      "6                  3.0             2.0                       1.0   \n",
      "7                  3.0             2.0                       1.0   \n",
      "8                  3.0             2.0                       1.0   \n",
      "9                  3.0             2.0                       1.0   \n",
      "\n",
      "   Time (Logistic)  Time (SVM)  Time (Random Forest)  \n",
      "0              3.0         1.0                   2.0  \n",
      "1              3.0         1.0                   2.0  \n",
      "2              3.0         1.0                   2.0  \n",
      "3              2.0         1.0                   3.0  \n",
      "4              2.0         1.0                   3.0  \n",
      "5              3.0         1.0                   2.0  \n",
      "6              3.0         1.0                   2.0  \n",
      "7              3.0         1.0                   2.0  \n",
      "8              2.0         1.0                   3.0  \n",
      "9              3.0         1.0                   2.0  \n",
      "\n",
      "Final Ranks Data:\n",
      "      Classifier  Accuracy Rank  F1 Score Rank  Time Rank\n",
      "0       Logistic            2.9            2.9        2.7\n",
      "1            SVM            2.1            2.1        1.0\n",
      "2  Random Forest            1.0            1.0        2.3\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store fold data and rank data\n",
    "fold_data_list = []\n",
    "rank_data_list = []\n",
    "\n",
    "for train_index, test_index in cv.split(X, Y):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train_cv, Y_test_cv = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    logic_classifier.fit(X_train_cv, Y_train_cv)\n",
    "    svm_classifier.fit(X_train_cv, Y_train_cv)\n",
    "    rf_classifier.fit(X_train_cv, Y_train_cv)\n",
    "\n",
    "    # Measuring the accuracy of the classifiers\n",
    "    Data_of_accuracy[iteration, 0] = logic_classifier.score(X_test_cv, Y_test_cv)\n",
    "    Data_of_accuracy[iteration, 1] = svm_classifier.score(X_test_cv, Y_test_cv)\n",
    "    Data_of_accuracy[iteration, 2] = rf_classifier.score(X_test_cv, Y_test_cv)\n",
    "\n",
    "    y_pred_logic = logic_classifier.predict(X_test_cv)\n",
    "    y_pred_svm = svm_classifier.predict(X_test_cv)\n",
    "    y_pred_rf = rf_classifier.predict(X_test_cv)\n",
    "\n",
    "    # Measuring the f1-score of the classifiers\n",
    "    Data_of_f1[iteration, 0] = f1_score(Y_test_cv, y_pred_logic)\n",
    "    Data_of_f1[iteration, 1] = f1_score(Y_test_cv, y_pred_svm)\n",
    "    Data_of_f1[iteration, 2] = f1_score(Y_test_cv, y_pred_rf)\n",
    "\n",
    "    start_time_logic = time.time()\n",
    "    logic_classifier.fit(X_train_cv, Y_train_cv)\n",
    "    time_logic = time.time() - start_time_logic\n",
    "\n",
    "    start_time_svm = time.time()\n",
    "    svm_classifier.fit(X_train_cv, Y_train_cv)\n",
    "    time_svm = time.time() - start_time_svm\n",
    "\n",
    "    start_time_rf = time.time()\n",
    "    rf_classifier.fit(X_train_cv, Y_train_cv)\n",
    "    time_rf = time.time() - start_time_rf\n",
    "\n",
    "    # Measuring time taken for each classifier to build\n",
    "    Data_of_time[iteration, 0] = time_logic\n",
    "    Data_of_time[iteration, 1] = time_svm\n",
    "    Data_of_time[iteration, 2] = time_rf\n",
    "\n",
    "    # Ranking the classifiers for each metric\n",
    "    accuracy_ranks[iteration, :] = np.argsort(np.argsort(-Data_of_accuracy[iteration, :])) + 1\n",
    "    f1_ranks[iteration, :] = np.argsort(np.argsort(-Data_of_f1[iteration, :])) + 1\n",
    "    time_ranks[iteration, :] = np.argsort(np.argsort(Data_of_time[iteration, :])) + 1\n",
    "\n",
    "    iteration += 1\n",
    "    fold_data = [iteration,\n",
    "                 Data_of_accuracy[iteration - 1, 0], Data_of_accuracy[iteration - 1, 1], Data_of_accuracy[iteration - 1, 2],\n",
    "                 Data_of_f1[iteration - 1, 0], Data_of_f1[iteration - 1, 1], Data_of_f1[iteration - 1, 2],\n",
    "                 Data_of_time[iteration - 1, 0], Data_of_time[iteration - 1, 1], Data_of_time[iteration - 1, 2]]\n",
    "    fold_data_list.append(fold_data)\n",
    "\n",
    "    rank_data = [iteration,\n",
    "                 accuracy_ranks[iteration - 1, 0], accuracy_ranks[iteration - 1, 1], accuracy_ranks[iteration - 1, 2],\n",
    "                 f1_ranks[iteration - 1, 0], f1_ranks[iteration - 1, 1], f1_ranks[iteration - 1, 2],\n",
    "                 time_ranks[iteration - 1, 0], time_ranks[iteration - 1, 1], time_ranks[iteration - 1, 2]]\n",
    "    rank_data_list.append(rank_data)\n",
    "\n",
    "# Create DataFrames from the lists\n",
    "fold_df = pd.DataFrame(fold_data_list, columns=headers)\n",
    "rank_df = pd.DataFrame(rank_data_list, columns=headers)\n",
    "\n",
    "# Calculate the average and standard deviation values for each metric\n",
    "average_accuracy = np.mean(Data_of_accuracy, axis=0)\n",
    "std_accuracy = np.std(Data_of_accuracy, axis=0)\n",
    "average_f1 = np.mean(Data_of_f1, axis=0)\n",
    "std_f1 = np.std(Data_of_f1, axis=0)\n",
    "average_time = np.mean(Data_of_time, axis=0)\n",
    "std_time = np.std(Data_of_time, axis=0)\n",
    "\n",
    "print(\"\\nAverage Accuracy:\", average_accuracy)\n",
    "print(\"Standard Deviation Accuracy:\", std_accuracy)\n",
    "print(\"\\nAverage F1 Score:\", average_f1)\n",
    "print(\"Standard Deviation F1 Score:\", std_f1)\n",
    "print(\"\\nAverage Time:\", average_time)\n",
    "print(\"Standard Deviation Time:\", std_time)\n",
    "\n",
    "# Calculate the average ranking of classifiers across all the metrics\n",
    "final_ranks_data = [\n",
    "    [\"Logistic\", np.mean(accuracy_ranks[:, 0]), np.mean(f1_ranks[:, 0]), np.mean(time_ranks[:, 0])],\n",
    "    [\"SVM\", np.mean(accuracy_ranks[:, 1]), np.mean(f1_ranks[:, 1]), np.mean(time_ranks[:, 1])],\n",
    "    [\"Random Forest\", np.mean(accuracy_ranks[:, 2]), np.mean(f1_ranks[:, 2]), np.mean(time_ranks[:, 2])]\n",
    "]\n",
    "final_ranks_df = pd.DataFrame(final_ranks_data, columns=final_rank_headers)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"\\nFold Data:\")\n",
    "print(fold_df)\n",
    "print(\"\\nRank Data:\")\n",
    "print(rank_df)\n",
    "print(\"\\nFinal Ranks Data:\")\n",
    "print(final_ranks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c7d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friedman test statistic of accuracy metric is: 18.2\n",
      "null hypothesis is rejected\n",
      "critical_difference: 1.0478214542564015\n",
      "Difference between Logistic Regression and SVM: 0.7999999999999998\n",
      "Classifier Logistic Regression and SVM do not have a significant difference.\n",
      "Difference between Logistic Regression and Random Forest: 1.9\n",
      "Classifier Logistic Regression and Random Forest have a significant difference.\n",
      "Difference between SVM and Random Forest: 1.1\n",
      "Classifier SVM and Random Forest have a significant difference.\n"
     ]
    }
   ],
   "source": [
    "#Using the Nemeth and Friedman tests to determine the accuracy metric\n",
    "\n",
    "for i in range (0,3):\n",
    "    Sum_of_squared_differences_for_accuracy_1=(np.mean(accuracy_ranks[:,i]) - (k + 1) / 2)**2 +Sum_of_squared_differences_for_accuracy_1\n",
    "Sum_of_squared_differences_for_accuracy_1=n*Sum_of_squared_differences_for_accuracy_1\n",
    "#print(Sum_of_squared_differences_for_accuracy_1)\n",
    "\n",
    "for i in range (0,10):\n",
    "  for j in range (0,3):\n",
    "    Sum_of_squared_differences_for_accuracy_2 =((accuracy_ranks[i,j]) - ((k + 1) / 2))**2+ Sum_of_squared_differences_for_accuracy_2\n",
    "Sum_of_squared_differences_for_accuracy_2=(1/(n*(k-1)))*Sum_of_squared_differences_for_accuracy_2\n",
    "#print(Sum_of_squared_differences_for_accuracy_2)\n",
    "\n",
    "friedman_statistic_accuracy=Sum_of_squared_differences_for_accuracy_1/Sum_of_squared_differences_for_accuracy_2\n",
    "print(f\"friedman test statistic of accuracy metric is: {friedman_statistic_accuracy}\")\n",
    "\n",
    "if friedman_statistic_accuracy>critical_value:\n",
    "  print(\"null hypothesis is rejected\")\n",
    "  critical_difference=q*np.sqrt((k*(k+1))/(6*n))\n",
    "  print(f\"critical_difference: {critical_difference}\")\n",
    "  for i in range(k):\n",
    "      for j in range(i + 1, k):\n",
    "          difference = np.abs(np.mean(accuracy_ranks[:,i]) - np.mean(accuracy_ranks[:,j]))\n",
    "          print(f\"Difference between {Classifiers[i]} and {Classifiers[j]}: {difference}\")\n",
    "\n",
    "          if difference > critical_difference:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} have a significant difference.\")\n",
    "          else:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} do not have a significant difference.\")\n",
    "\n",
    "else:\n",
    "  print(\"null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a8d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friedman test statistic of F1-Score metric is: 18.2\n",
      "null hypothesis is rejected\n",
      "critical_difference: 1.0478214542564015\n",
      "Difference between Logistic Regression and SVM: 0.7999999999999998\n",
      "Classifier Logistic Regression and SVM do not have a significant difference.\n",
      "Difference between Logistic Regression and Random Forest: 1.9\n",
      "Classifier Logistic Regression and Random Forest have a significant difference.\n",
      "Difference between SVM and Random Forest: 1.1\n",
      "Classifier SVM and Random Forest have a significant difference.\n"
     ]
    }
   ],
   "source": [
    "#Applying Nemeth and Friedman tests to the f1-score mertic\n",
    "\n",
    "for i in range (0,3):\n",
    "    Sum_of_squared_differences_for_f1_1=(np.mean(f1_ranks[:,i]) - (k + 1) / 2)**2 +Sum_of_squared_differences_for_f1_1\n",
    "Sum_of_squared_differences_for_f1_1=n*Sum_of_squared_differences_for_f1_1\n",
    "#print(Sum_of_squared_differences_for_f1_1)\n",
    "\n",
    "for i in range (0,10):\n",
    "  for j in range (0,3):\n",
    "    Sum_of_squared_differences_for_f1_2 =((f1_ranks[i,j]) - ((k + 1) / 2))**2+ Sum_of_squared_differences_for_f1_2\n",
    "Sum_of_squared_differences_for_f1_2=(1/(n*(k-1)))*Sum_of_squared_differences_for_f1_2\n",
    "#print(Sum_of_squared_differences_for_f1_2)\n",
    "\n",
    "friedman_statistic_f1=Sum_of_squared_differences_for_f1_1/Sum_of_squared_differences_for_f1_2\n",
    "print(f\"friedman test statistic of F1-Score metric is: {friedman_statistic_f1}\")\n",
    "\n",
    "if friedman_statistic_f1>critical_value:\n",
    "  print(\"null hypothesis is rejected\")\n",
    "  critical_difference=q*np.sqrt((k*(k+1))/(6*n))\n",
    "  print(f\"critical_difference: {critical_difference}\")\n",
    "  for i in range(k):\n",
    "      for j in range(i + 1, k):\n",
    "          difference = np.abs(np.mean(f1_ranks[:,i]) - np.mean(f1_ranks[:,j]))\n",
    "          print(f\"Difference between {Classifiers[i]} and {Classifiers[j]}: {difference}\")\n",
    "\n",
    "          if difference > critical_difference:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} have a significant difference.\")\n",
    "          else:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} do not have a significant difference.\")\n",
    "\n",
    "else:\n",
    "  print(\"null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f6f37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friedman test statistic of time metric is: 15.8\n",
      "null hypothesis is rejected\n",
      "critical_difference: 1.0478214542564015\n",
      "Difference between Logistic Regression and SVM: 1.7000000000000002\n",
      "Classifier Logistic Regression and SVM have a significant difference.\n",
      "Difference between Logistic Regression and Random Forest: 0.40000000000000036\n",
      "Classifier Logistic Regression and Random Forest do not have a significant difference.\n",
      "Difference between SVM and Random Forest: 1.2999999999999998\n",
      "Classifier SVM and Random Forest have a significant difference.\n"
     ]
    }
   ],
   "source": [
    "#Applying the Nemeth and Friedman tests for time metrics\n",
    "\n",
    "for i in range (0,3):\n",
    "    Sum_of_squared_differences_for_Time_1=(np.mean(time_ranks[:,i]) - (k + 1) / 2)**2 +Sum_of_squared_differences_for_Time_1\n",
    "Sum_of_squared_differences_for_Time_1=n*Sum_of_squared_differences_for_Time_1\n",
    "#print(Sum_of_squared_differences_for_Time_1)\n",
    "\n",
    "for i in range (0,10):\n",
    "  for j in range (0,3):\n",
    "    Sum_of_squared_differences_for_Time_2 =((time_ranks[i,j]) - ((k + 1) / 2))**2+ Sum_of_squared_differences_for_Time_2\n",
    "Sum_of_squared_differences_for_Time_2=(1/(n*(k-1)))*Sum_of_squared_differences_for_Time_2\n",
    "#print(Sum_of_squared_differences_for_Time_2)\n",
    "\n",
    "friedman_statistic_time=Sum_of_squared_differences_for_Time_1/Sum_of_squared_differences_for_Time_2\n",
    "print(f\"friedman test statistic of time metric is: {friedman_statistic_time}\")\n",
    "\n",
    "if friedman_statistic_time>critical_value:\n",
    "  print(\"null hypothesis is rejected\")\n",
    "  critical_difference=q*np.sqrt((k*(k+1))/(6*n))\n",
    "  print(f\"critical_difference: {critical_difference}\")\n",
    "  for i in range(k):\n",
    "      for j in range(i + 1, k):\n",
    "          difference = np.abs(np.mean(time_ranks[:,i]) - np.mean(time_ranks[:,j]))\n",
    "          print(f\"Difference between {Classifiers[i]} and {Classifiers[j]}: {difference}\")\n",
    "\n",
    "          if difference > critical_difference:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} have a significant difference.\")\n",
    "          else:\n",
    "              print(f\"Classifier {Classifiers[i]} and {Classifiers[j]} do not have a significant difference.\")\n",
    "\n",
    "else:\n",
    "  print(\"null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11082c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
